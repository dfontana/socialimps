+++
date = "2018-04-19"
draft = true
title = "Professional Ethics"
author = "Sam"

categories = ["Topics"] 
weight = 2 
type = "post" 
+++

Professional Ethics in *Black Mirror: Hated in the Nation*
----------------------------------------------------------
In *Hated in the Nation*, Rasmus Sjolberg leads the development team for the Autonomous Drone Insects (ADIs). 
Around two thirds of the way through the episode, it is revealed that Sjolberg was aware of the government using the ADIs to conduct surveillance. 
While the episode doesn't explicitly explore this, it does make the audience question his actions. 
Should he have continued the project knowing that the government would use them in such a manner? 
Or should he have rejected the government funding? 
Should he have alerted the public?
There wasn't much discussion in the episode about these questions, as there were other, more pressing matters, but it does provide a scenario for viewers to consider.
For Sjolberg to have decided to become a whistle-blower, he would have had to decide whether the government surveillance has the potential to harm the public.
From the information provided in the show, we don't know Sjolberg's assessment of the situation. For all we know, he decided that the potential harm of not implementing artificial bees outweighed the potential harm of government surveillance.
Alternatively, his motives could have been more self centered, wanting the funding to build his business. It is impossible to say without more information, but the show does pose the question, even if it doesn't answer it.

Additionally, Sjolberg's work can be analyzed using the Software Engineering Code of Ethics (although software was not the entirety of the work he performed, it is still relevant), it is clear that he could have done better overall.
Sjolberg clearly, albeit unintentionally, violates clause 1.03, in that his work did harm the public good. It is reasonable to expect him to take extraordinary measures to test and validate the ADIs - after all, these are robots being release in massive quantities into the public. Sjolberg failed to adequatly ensure the security and safety of his system, which lead to thousands of deaths.
This also fails clause 3.10 - Sjolberg did not test the software adequately enough to prevent a malicious actor from gaining control to the entire system.
While Sjolberg was not at fault entirely, the issues presented with the ADIs could have *potentially* been prevented with better development ethics.
